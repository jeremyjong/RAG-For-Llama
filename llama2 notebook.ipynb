{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\.conda\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import transformer classes for generaiton\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "# Import torch for datatype attributes \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable to hold llama2 weights naming \n",
    "name = \"elyza/ELYZA-japanese-Llama-2-7b-instruct\"\n",
    "# Set auth token variable from hugging face \n",
    "auth_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\.conda\\envs\\llm\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(name, \n",
    "    cache_dir='./model/', use_auth_token=auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\.conda\\envs\\llm\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [03:23<00:00, 101.59s/it]\n",
      "c:\\Users\\jerem\\.conda\\envs\\llm\\lib\\site-packages\\transformers\\utils\\hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "\"\"\"model = AutoModelForCausalLM.from_pretrained(name, \n",
    "    cache_dir='./model/', use_auth_token=auth_token, torch_dtype=torch.float16, \n",
    "    rope_scaling={\"type\": \"dynamic\", \"factor\": 2}, load_in_8bit=False) \"\"\"\n",
    "# Create model\n",
    "model = AutoModelForCausalLM.from_pretrained(name, \n",
    "    cache_dir='./model/', use_auth_token=auth_token, torch_dtype=\"auto\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"あなたは誠実で優秀な日本人のアシスタントです。\"\n",
    "text = \"世界一番早い車を教えてください\"\n",
    "\n",
    "# Setup a prompt \n",
    "prompt = \"{bos_token}{b_inst} {system}{prompt} {e_inst} \".format(\n",
    "    bos_token=tokenizer.bos_token,\n",
    "    b_inst=B_INST,\n",
    "    system=f\"{B_SYS}{DEFAULT_SYSTEM_PROMPT}{E_SYS}\",\n",
    "    prompt=text,\n",
    "    e_inst=E_INST,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\.conda\\envs\\llm\\lib\\site-packages\\transformers\\generation\\utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界最速の車は、スカイラインGT-R (R35) の最高速度が350km/hであるため、この車種となります。\n",
      "\n",
      "ただし、公道を走行する場合、最高速度は走行に支障をきたすため、制限速度によって規制されます。\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Pass the prompt to the tokenizer\n",
    "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    # Setup the text streamer \n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "    # Actually run the thing\n",
    "    output_ids = model.generate(token_ids.to(model.device), streamer=streamer, \n",
    "                            use_cache=True, max_new_tokens=float('inf'),\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界最速の車は、スカイラインGT-R (R35) の最高速度が350km/hであるため、この車種となります。\n",
      "\n",
      "ただし、公道を走行する場合、最高速度は走行に支障をきたすため、制限速度によって規制されます。\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prompt wrapper...but for llama index\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "# Create a system prompt \n",
    "system_prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "あなたは親切で、礼儀正しく、誠実なアシスタントです。 常に次のように答えます\n",
    "安全を確保しながら、できるだけ役に立ちます。 回答には以下を含めてはいけません\n",
    "有害、非倫理的、人種差別的、性差別的、有毒、危険、または違法なコンテンツ。\n",
    "回答は社会的に偏見がなく、本質的に前向きなものであることを確認してください。\n",
    "\n",
    "質問が意味をなさない場合、または事実に一貫性がない場合は、なぜ正しくないことに答える代わりに説明してください。\n",
    "答えがわからない場合質問に対して、虚偽の情報を共有しないでください。\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "# Throw together the query wrapper\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"{query_str} [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello [/INST]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete the query prompt\n",
    "query_wrapper_prompt.format(query_str='hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the llama index HF Wrapper\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "# Create a HF LLM using the llama index wrapper \n",
    "llm = HuggingFaceLLM(context_window=4096,\n",
    "                    max_new_tokens=256,\n",
    "                    system_prompt=system_prompt,\n",
    "                    query_wrapper_prompt=query_wrapper_prompt,\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in embeddings wrapper\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "# Bring in HF embeddings - need these to represent document chunks\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nembeddings=LangchainEmbedding(\\n    HuggingFaceEmbeddings(model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\")\\n)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and dl embeddings instance  \n",
    "\n",
    "\n",
    "embeddings=LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "embeddings=LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\")\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in stuff to change service context\n",
    "from llama_index import set_global_service_context\n",
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new service context instance\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    llm=llm,\n",
    "    embed_model=embeddings\n",
    ")\n",
    "# And set the service context\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deps to load documents \n",
    "from llama_index import VectorStoreIndex, download_loader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PDF Loader \n",
    "PyMuPDFReader = download_loader(\"PyMuPDFReader\")\n",
    "# Create PDF Loader\n",
    "loader = PyMuPDFReader()\n",
    "# Load documents \n",
    "documents = loader.load(file_path=Path('./data/2024_1q_summary_jp.pdf'), metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index - we'll be able to query this in a sec\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup index query engine using LLM \n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out a query in natural\n",
    "response = query_engine.query(\"2024年の配当金を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024年の配当金は、25円です。\n",
      "\n",
      "なぜなら、2024年3月期の連結業績予想 (2023年4月1日～2024年3月31日) の「３．2024年３月期の連結業績予想」の項目に、「営業収益: 38,000,000」、「営業利益: 3,000,000」、「税引前利益: 3,690,000」、「親会社の所有者に帰属する当期利益: 3,690,000」とあるため、営業収益の3％の配当金は、38,000,000×3�����\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' 2024年の配当金は、25円です。\\n\\nなぜなら、2024年3月期の連結業績予想 (2023年4月1日～2024年3月31日) の「３．2024年３月期の連結業績予想」の項目に、「営業収益: 38,000,000」、「営業利益: 3,000,000」、「税引前利益: 3,690,000」、「親会社の所有者に帰属する当期利益: 3,690,000」とあるため、営業収益の3％の配当金は、38,000,000×3�����', source_nodes=[NodeWithScore(node=TextNode(id_='ded1d1c3-cc0f-4269-8e2c-bb2db53c19c7', embedding=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '5'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f108f538-a127-4f7b-b2e9-1e180093e87e', node_type=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '5'}, hash='778a0b6aa365e552c5b6f5e2ba32173de8a7f0fb269009f233de6e26360e48b3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2db6b181-8f05-4d6f-b2b5-cc4716a9da4d', node_type=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '5'}, hash='4759a524e0b3e5b5d64c5c7215f914f6c9cbf40fb6399ea80bfc533d422d1739')}, hash='078895afd797bb415ab486daa016330cecbb7bedc288551ec9c56c479a1610ee', text='要約四半期連結財務諸表及び主な注記\\n１．要約四半期連結財政状態計算書\\n（単位：百万円）\\n前連結会計年度\\n（2023年３月31日）\\n当第１四半期\\n連結会計期間\\n（2023年６月30日）\\n資産\\n流動資産\\n現金及び現金同等物\\n7,516,966\\n7,906,447\\n営業債権及びその他の債権\\n3,586,130\\n3,579,181\\n金融事業に係る債権\\n8,279,806\\n9,244,379\\nその他の金融資産\\n1,715,675\\n2,287,272\\n棚卸資産\\n4,255,614\\n4,671,910\\n未収法人所得税\\n218,704\\n245,936\\nその他の流動資産\\n886,885\\n1,008,874\\n流動資産合計\\n26,459,781\\n28,943,999\\n非流動資産\\n持分法で会計処理されている投資\\n5,227,345\\n5,143,351\\n金融事業に係る債権\\n16,491,045\\n18,213,507\\nその他の金融資産\\n10,556,431\\n11,460,296\\n有形固定資産\\n土地\\n1,426,370\\n1,446,910\\n建物\\n5,464,811\\n5,654,705\\n機械装置\\n14,796,619\\n15,591,572\\n賃貸用車両及び器具\\n6,774,427\\n7,227,875\\n建設仮勘定\\n846,866\\n852,978\\n小計\\n29,309,093\\n30,774,041\\n減価償却累計額及び減損損失\\n累計額＜控除＞\\n△16,675,119\\n△17,482,649\\n有形固定資産合計\\n12,633,974\\n13,291,392\\n使用権資産\\n491,368\\n516,601\\n無形資産\\n1,249,122\\n1,299,050\\n繰延税金資産\\n387,427\\n434,307\\nその他の非流動資産\\n806,687\\n828,706\\n非流動資産合計\\n47,843,399\\n51,187,209\\n資産合計\\n74,303,180\\n80,131,208\\nトヨタ自動車㈱ ( 7203) ', start_char_idx=0, end_char_idx=835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.3335444587853547), NodeWithScore(node=TextNode(id_='82bfb132-6538-4c13-9def-93aa9503ee8e', embedding=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '2'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f0a9d335-1442-4797-8595-1b409f1da08a', node_type=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '2'}, hash='65300a0daf59d45a1a06c1fa2af4b237845cd65efcc0b6e2f92710208ff8cbe3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7db28fb5-bbeb-4af7-9f69-e86d96c53a56', node_type=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '2'}, hash='f2708c3ce0b4d473965e432c03b67e6db80da4b9b44273137f7fddf186207289'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d62228f0-eff9-415c-91f6-e9f0cd3b61c6', node_type=None, metadata={'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '2'}, hash='642674d0f0aeb7968024e5c03ce184e34f67068cc39f518bc4b88c11079585a7')}, hash='6f359788cd72d3ad3ccdffde99732b3fc48a8b7ba818e9fbe2fc1ad906e3453d', text='△18.2\\n736,820 △17.9 1,688,311\\n47.3\\n基本的１株当たり\\n親会社の所有者に帰属する\\n四半期利益\\n希薄化後１株当たり\\n親会社の所有者に帰属する\\n四半期利益\\n円\\n銭\\n円\\n銭\\n2024年３月期第１四半期\\n96.74\\n96.74\\n2023年３月期第１四半期\\n53.65\\n53.65\\n（２）連結財政状態\\n資産合計\\n資本合計\\n親会社の所有者に\\n帰属する持分\\n親会社所有者\\n帰属持分比率\\n百万円\\n百万円\\n百万円\\n％\\n2024年３月期第１四半期\\n80,131,208\\n31,274,404\\n30,330,063\\n37.9\\n2023年３月期\\n74,303,180\\n29,264,213\\n28,338,706\\n38.1\\n２．配当の状況\\n年間配当金\\n第１四半期末\\n第２四半期末\\n第３四半期末\\n期末\\n合計\\n円\\n銭\\n円\\n銭\\n円\\n銭\\n円\\n銭\\n円\\n銭\\n2023年３月期\\n－\\n25.00\\n－\\n35.00\\n60.00\\n2024年３月期\\n－\\n2024年３月期(予想)\\n－\\n－\\n－\\n－\\n(注) 直近に公表されている配当予想からの修正の有無\\n：無\\n３．2024年３月期の連結業績予想（2023年４月１日～2024年３月31日）\\n（％表示は、対前期増減率）\\n営業収益\\n営業利益\\n税引前利益\\n親会社の所有者に\\n帰属する当期利益\\n基本的１株当たり\\n親会社の所有者に\\n帰属する当期利益\\n百万円\\n％\\n百万円\\n％\\n百万円\\n％\\n百万円\\n％\\n円\\n銭\\n通期\\n38,000,000\\n2.3\\n3,000,000\\n10.1\\n3,690,000\\n0.6\\n2,580,000\\n5.2\\n190.41\\n(注)', start_char_idx=627, end_char_idx=1310, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.3329975653423806)], metadata={'ded1d1c3-cc0f-4269-8e2c-bb2db53c19c7': {'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '5'}, '82bfb132-6538-4c13-9def-93aa9503ee8e': {'total_pages': 13, 'file_path': WindowsPath('data/2024_1q_summary_jp.pdf'), 'source': '2'}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LlamaIndex object\n",
    "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex\n",
    "\n",
    "# Index your PDFs\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index - we'll be able to query this in a sec\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"トヨタ⾃動⾞株式会社の決算サマリーを教えてください\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 承知しました。\n",
      "\n",
      "トヨタ⾃動⾞株式会社の決算サマリーは以下の通りです。\n",
      "\n",
      "1\n",
      "1\n",
      "2023年8⽉1⽇ヴェルファイア\n",
      "トヨタ⾃動⾞株式会社\n",
      "2024年3⽉期\n",
      "第1四半期決算\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "2023年8⽉1⽇ヴェルファイア\n",
      "トヨタ⾃動⾞株式会社\n",
      "2024年3⽉期\n",
      "第1四半期決算\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
